{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3409f4f2-2450-46bc-91e2-e4e154c554e6",
   "metadata": {},
   "source": [
    "# 주식 및 ETF 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a838f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pykrx in e:\\아경\\ai\\python38\\lib\\site-packages (1.0.45)\n",
      "Collecting pykrx\n",
      "  Downloading pykrx-1.0.48-py3-none-any.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.9/60.9 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (2.32.3)\n",
      "Requirement already satisfied: pandas in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (1.5.3)\n",
      "Requirement already satisfied: datetime in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (5.5)\n",
      "Requirement already satisfied: numpy in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (1.24.4)\n",
      "Requirement already satisfied: xlrd in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (2.0.1)\n",
      "Requirement already satisfied: deprecated in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (1.2.14)\n",
      "Requirement already satisfied: multipledispatch in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (3.6.0)\n",
      "Requirement already satisfied: zope.interface in e:\\아경\\ai\\python38\\lib\\site-packages (from datetime->pykrx) (6.4.post2)\n",
      "Requirement already satisfied: pytz in e:\\아경\\ai\\python38\\lib\\site-packages (from datetime->pykrx) (2023.3.post1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\아경\\ai\\python38\\lib\\site-packages (from deprecated->pykrx) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\아경\\ai\\python38\\lib\\site-packages (from requests->pykrx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\아경\\ai\\python38\\lib\\site-packages (from requests->pykrx) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\아경\\ai\\python38\\lib\\site-packages (from requests->pykrx) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\아경\\ai\\python38\\lib\\site-packages (from requests->pykrx) (2024.6.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\아경\\ai\\python38\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->pykrx) (1.16.0)\n",
      "Requirement already satisfied: setuptools in e:\\아경\\ai\\python38\\lib\\site-packages (from zope.interface->datetime->pykrx) (49.2.1)\n",
      "Downloading pykrx-1.0.48-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 13.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pykrx\n",
      "  Attempting uninstall: pykrx\n",
      "    Found existing installation: pykrx 1.0.45\n",
      "    Uninstalling pykrx-1.0.45:\n",
      "      Successfully uninstalled pykrx-1.0.45\n",
      "Successfully installed pykrx-1.0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pykrx\n",
    "# pip install/ beautifulsoup4 pandas openpyxl selenium webdriver-manager pykrx sqlalchemy pymysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31315c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: configparser in e:\\아경\\ai\\python38\\lib\\site-packages (7.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install configparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed37cfd1-8643-468d-b27a-8dc573731d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.ini 파일을 찾았습니다.\n",
      "Username: root, Password: @waren2ss, Host: 127.0.0.1\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "from pykrx import stock\n",
    "import datetime\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import numpy as np\n",
    "import configparser\n",
    "\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "# ConfigParser 객체 생성\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# config.ini 파일 경로 설정\n",
    "config_file_path = 'E:\\\\AI\\\\pythonProject\\\\venv\\\\masicsplit\\\\config.ini'\n",
    "\n",
    "# 경로가 올바른지 확인\n",
    "if os.path.exists(config_file_path):\n",
    "    print(\"config.ini 파일을 찾았습니다.\")\n",
    "    config.read(config_file_path)\n",
    "else:\n",
    "    print(\"config.ini 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "\n",
    "# mysql 섹션에서 설정값 가져오기\n",
    "try:\n",
    "    username = config['mysql']['user']\n",
    "    password = config['mysql']['password']\n",
    "    host = config['mysql']['host']\n",
    "    database=config['mysql']['database']\n",
    "    print(f\"Username: {username}, Password: {password}, Host: {host}\")\n",
    "except KeyError as e:\n",
    "    print(f\"설정 파일에서 키를 찾을 수 없습니다: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"기타 오류 발생: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d2acfc",
   "metadata": {},
   "source": [
    "# 주식 및 ETF 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e928c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테이블 생성 함수\n",
    "def create_tables():\n",
    "    cur.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS stock_data (\n",
    "        ticker VARCHAR(10),\n",
    "        name VARCHAR(100),\n",
    "        date DATE,\n",
    "        open FLOAT,\n",
    "        high FLOAT,\n",
    "        low FLOAT,\n",
    "        close FLOAT,\n",
    "        volume BIGINT,\n",
    "        value BIGINT,\n",
    "        market_cap BIGINT,\n",
    "        shares_outstanding BIGINT,\n",
    "        PER FLOAT,\n",
    "        PBR FLOAT,\n",
    "        dividend FLOAT,\n",
    "        BPS FLOAT,\n",
    "        EPS FLOAT,\n",
    "        DPS FLOAT,\n",
    "        normalized_value FLOAT,\n",
    "        PRIMARY KEY (ticker, date)\n",
    "    )\n",
    "    ''')\n",
    "    cur.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS ticker_list (\n",
    "        ticker VARCHAR(10) PRIMARY KEY,\n",
    "        market VARCHAR(10),\n",
    "        name VARCHAR(100),\n",
    "        last_updated DATE,\n",
    "        is_delisted BOOLEAN DEFAULT FALSE\n",
    "    )\n",
    "    ''')\n",
    "    cur.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS ticker_status (\n",
    "        ticker VARCHAR(10) PRIMARY KEY,\n",
    "        status VARCHAR(20)\n",
    "    )\n",
    "    ''')\n",
    "create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e8fc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19950102\n",
      "956 19950701\n",
      "1132 19951228\n",
      "1190 19960625\n",
      "1758 19961222\n",
      "1827 19970620\n",
      "1906 19971217\n",
      "1930 19980615\n",
      "1941 19981212\n",
      "2003 19990610\n",
      "2117 19991207\n",
      "2298 20000604\n",
      "2440 20001201\n",
      "2525 20010530\n",
      "2638 20011126\n",
      "2773 20020525\n",
      "2848 20021121\n",
      "2895 20030520\n",
      "2944 20031116\n",
      "2983 20040514\n",
      "3016 20041110\n",
      "3061 20050509\n",
      "3121 20051105\n",
      "3164 20060504\n",
      "3214 20061031\n",
      "3257 20070429\n",
      "3322 20071026\n",
      "3361 20080423\n",
      "3404 20081020\n",
      "3428 20090418\n",
      "3467 20091015\n",
      "3519 20100413\n",
      "3571 20101010\n",
      "3625 20110408\n",
      "3664 20111005\n",
      "3702 20120402\n",
      "3720 20120929\n",
      "3740 20130328\n",
      "3758 20130924\n",
      "3785 20140323\n",
      "3807 20140919\n",
      "3865 20150318\n",
      "3932 20150914\n",
      "4002 20160312\n",
      "4034 20160908\n",
      "4087 20170307\n",
      "4137 20170903\n",
      "4189 20180302\n",
      "4227 20180829\n",
      "4292 20190225\n",
      "4338 20190824\n",
      "4406 20200220\n",
      "4450 20200818\n",
      "4517 20210214\n",
      "4573 20210813\n",
      "4639 20220209\n",
      "4693 20220808\n",
      "4762 20230204\n",
      "4832 20230803\n",
      "4908 20240130\n",
      "4971 20240728\n"
     ]
    },
    {
     "ename": "InterfaceError",
     "evalue": "(0, '')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m name \u001b[38;5;241m=\u001b[39m stock\u001b[38;5;241m.\u001b[39mget_market_ticker_name(ticker)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;43m    INSERT INTO ticker_list (ticker, market, name) VALUES (\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;43m    ON DUPLICATE KEY UPDATE market=VALUES(market), name=VALUES(name)\u001b[39;49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m    INSERT INTO ticker_status (ticker, status) VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpending\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m    ON DUPLICATE KEY UPDATE status=VALUES(status)\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m, (ticker,))\n\u001b[0;32m     36\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "File \u001b[1;32me:\\아경\\AI\\Python38\\lib\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32me:\\아경\\AI\\Python38\\lib\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    320\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32me:\\아경\\AI\\Python38\\lib\\site-packages\\pymysql\\connections.py:562\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    561\u001b[0m     sql \u001b[38;5;241m=\u001b[39m sql\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 562\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCOMMAND\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOM_QUERY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_query_result(unbuffered\u001b[38;5;241m=\u001b[39munbuffered)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32me:\\아경\\AI\\Python38\\lib\\site-packages\\pymysql\\connections.py:843\u001b[0m, in \u001b[0;36mConnection._execute_command\u001b[1;34m(self, command, sql)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m:raise InterfaceError: If the connection is closed.\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;124;03m:raise ValueError: If no username was specified.\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock:\n\u001b[1;32m--> 843\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\u001b[38;5;241m.\u001b[39mInterfaceError(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    845\u001b[0m \u001b[38;5;66;03m# If the last query was unbuffered, make sure it finishes before\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;66;03m# sending new commands\u001b[39;00m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInterfaceError\u001b[0m: (0, '')"
     ]
    }
   ],
   "source": [
    "# 모든 티커 리스트를 저장할 집합\n",
    "all_tickers = set()\n",
    "\n",
    "# 시작 날짜와 현재 날짜 설정\n",
    "start_date = '19950102' # 이 시기부터 ticker list를 제공\n",
    "end_date = datetime.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# 모든 날짜에 대해 티커 리스트 가져오기\n",
    "current_date = datetime.datetime.strptime(start_date, '%Y%m%d')\n",
    "while current_date.strftime('%Y%m%d') <= end_date:\n",
    "    date_str = current_date.strftime('%Y%m%d')\n",
    "    try:\n",
    "        tickers_kosdaq = stock.get_market_ticker_list(date_str, market='KOSDAQ')\n",
    "        tickers_kospi = stock.get_market_ticker_list(date_str, market='KOSPI')\n",
    "        all_tickers.update(tickers_kosdaq)\n",
    "        all_tickers.update(tickers_kospi)\n",
    "        print(len(all_tickers), f'{date_str}')\n",
    "        time.sleep(0.8)\n",
    "    except Exception as e:\n",
    "        print(f\"Error on date {date_str}: {e}\")\n",
    "    current_date += datetime.timedelta(days=180)  # 180일 단위로 진행\n",
    "\n",
    "conn = pymysql.connect(host=host, user=username, password=password, db=database, charset='utf8')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 티커 목록을 MySQL에 저장\n",
    "for ticker in all_tickers:\n",
    "    market = 'KOSDAQ' if ticker in tickers_kosdaq else 'KOSPI'\n",
    "    name = stock.get_market_ticker_name(ticker)\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute('''\n",
    "            INSERT INTO ticker_list (ticker, market, name) VALUES (%s, %s, %s)\n",
    "            ON DUPLICATE KEY UPDATE market=VALUES(market), name=VALUES(name)\n",
    "            ''', (ticker, market, name))\n",
    "            \n",
    "            #cur.execute('''\n",
    "            #INSERT INTO ticker_status (ticker, status) VALUES (%s, 'pending')\n",
    "            #ON DUPLICATE KEY UPDATE status=VALUES(status)\n",
    "            #''', (ticker,))\n",
    "            conn.commit()\n",
    "    except pymysql.InterfaceError as e:\n",
    "        print(f\"InterfaceError: {e}, reconnecting...\")\n",
    "        conn = pymysql.connect(host=host, user=username, password=password, db=database, charset='utf8') # 재연결 시도\n",
    "    except pymysql.DatabaseError as e:\n",
    "        print(f\"DatabaseError: {e}\")\n",
    "        conn.rollback()  # 롤백하여 데이터 일관성 유지\n",
    "\n",
    "conn.close()\n",
    "print(\"모든 티커 목록이 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8419ab92",
   "metadata": {},
   "source": [
    "## Step 2: 데이터 갱신 및 새로운 티커 추가 (중단 후 재시작 가능)\n",
    "* 한번 실행한 경우 몇 거래일 뒤에 다시 실행해야 오류가 발생하지 않음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62aab686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.ini 파일을 찾았습니다.\n",
      "Username: root, Password: @waren2ss, Host: 127.0.0.1\n",
      "000020 already done\n",
      "000040 already done\n",
      "000050 already done\n",
      "000070 already done\n",
      "000080 already done\n",
      "000100 already done\n",
      "000120 already done\n",
      "000140 already done\n",
      "000150 already done\n",
      "000180 already done\n",
      "000210 already done\n",
      "000220 already done\n",
      "000230 already done\n",
      "000240 already done\n",
      "000250 already done\n",
      "000270 already done\n",
      "000300 already done\n",
      "000320 already done\n",
      "000370 already done\n",
      "000390 already done\n",
      "000400 already done\n",
      "000430 already done\n",
      "000440 already done\n",
      "000480 already done\n",
      "000490 already done\n",
      "000500 already done\n",
      "000520 already done\n",
      "000540 already done\n",
      "000590 already done\n",
      "000640 already done\n",
      "000650 already done\n",
      "000660 already done\n",
      "000670 already done\n",
      "000680 already done\n",
      "000700 already done\n",
      "000720 already done\n",
      "000760 already done\n",
      "000810 already done\n",
      "000850 already done\n",
      "000860 already done\n",
      "000880 already done\n",
      "000890 already done\n",
      "000910 already done\n",
      "000950 already done\n",
      "000970 already done\n",
      "000990 already done\n",
      "001000 already done\n",
      "001020 already done\n",
      "001040 already done\n",
      "001060 already done\n",
      "001070 already done\n",
      "001080 already done\n",
      "001120 already done\n",
      "001130 already done\n",
      "001140 already done\n",
      "001200 already done\n",
      "001210 already done\n",
      "001230 already done\n",
      "001250 already done\n",
      "001260 already done\n",
      "001270 already done\n",
      "001290 already done\n",
      "001340 already done\n",
      "001360 already done\n",
      "001380 already done\n",
      "001390 already done\n",
      "001420 already done\n",
      "001430 already done\n",
      "001440 already done\n",
      "001450 already done\n",
      "001460 already done\n",
      "001470 already done\n",
      "001500 already done\n",
      "001510 already done\n",
      "001520 already done\n",
      "001530 already done\n",
      "001540 already done\n",
      "001550 already done\n",
      "001560 already done\n",
      "001570 already done\n",
      "001620 already done\n",
      "001630 already done\n",
      "001680 already done\n",
      "001720 already done\n",
      "001740 already done\n",
      "001750 already done\n",
      "001770 already done\n",
      "001780 already done\n",
      "001790 already done\n",
      "001800 already done\n",
      "001810 already done\n",
      "001820 already done\n",
      "001840 already done\n",
      "001940 already done\n",
      "002020 already done\n",
      "002030 already done\n",
      "002070 already done\n",
      "002100 already done\n",
      "002140 already done\n",
      "002150 already done\n",
      "002170 already done\n",
      "002200 already done\n",
      "002210 already done\n",
      "002220 already done\n",
      "002230 already done\n",
      "002240 already done\n",
      "002290 already done\n",
      "002310 already done\n",
      "002320 already done\n",
      "002350 already done\n",
      "002360 already done\n",
      "002380 already done\n",
      "002390 already done\n",
      "002410 already done\n",
      "002420 already done\n",
      "002450 already done\n",
      "002460 already done\n",
      "002600 already done\n",
      "002620 already done\n",
      "002630 already done\n",
      "002680 already done\n",
      "002690 already done\n",
      "002700 already done\n",
      "002710 already done\n",
      "002720 already done\n",
      "002760 already done\n",
      "002780 already done\n",
      "002790 already done\n",
      "002800 already done\n",
      "002810 already done\n",
      "002820 already done\n",
      "002840 already done\n",
      "002870 already done\n",
      "002880 already done\n",
      "002900 already done\n",
      "002920 already done\n",
      "002960 already done\n",
      "002990 already done\n",
      "003000 already done\n",
      "003010 already done\n",
      "003030 already done\n",
      "003060 already done\n",
      "003070 already done\n",
      "003080 already done\n",
      "003090 already done\n",
      "003100 already done\n",
      "003120 already done\n",
      "003160 already done\n",
      "003200 already done\n",
      "003220 already done\n",
      "003230 already done\n",
      "003240 already done\n",
      "003280 already done\n",
      "003300 already done\n",
      "003310 already done\n",
      "003350 already done\n",
      "003380 already done\n",
      "003410 already done\n",
      "003460 already done\n",
      "003470 already done\n",
      "003480 already done\n",
      "003490 already done\n",
      "003520 already done\n",
      "003530 already done\n",
      "003540 already done\n",
      "003550 already done\n",
      "003560 already done\n",
      "003570 already done\n",
      "003580 already done\n",
      "003610 already done\n",
      "003620 already done\n",
      "003650 already done\n",
      "003670 already done\n",
      "003680 already done\n",
      "003690 already done\n",
      "003720 already done\n",
      "003780 already done\n",
      "003800 already done\n",
      "003830 already done\n",
      "003850 already done\n",
      "003920 already done\n",
      "003960 already done\n",
      "004000 already done\n",
      "004020 already done\n",
      "004060 already done\n",
      "004080 already done\n",
      "004090 already done\n",
      "004100 already done\n",
      "004140 already done\n",
      "004150 already done\n",
      "004170 already done\n",
      "004250 already done\n",
      "004270 already done\n",
      "004310 already done\n",
      "004360 already done\n",
      "004370 already done\n",
      "004380 already done\n",
      "004410 already done\n",
      "004430 already done\n",
      "004440 already done\n",
      "004450 already done\n",
      "004490 already done\n",
      "004540 already done\n",
      "004560 already done\n",
      "004590 already done\n",
      "004650 already done\n",
      "004690 already done\n",
      "004700 already done\n",
      "004710 already done\n",
      "004720 already done\n",
      "004770 already done\n",
      "004780 already done\n",
      "004800 already done\n",
      "004830 already done\n",
      "004840 already done\n",
      "004870 already done\n",
      "004890 already done\n",
      "004910 already done\n",
      "004920 already done\n",
      "004960 already done\n",
      "004970 already done\n",
      "004980 already done\n",
      "004990 already done\n",
      "005010 already done\n",
      "005030 already done\n",
      "005070 already done\n",
      "005090 already done\n",
      "005110 already done\n",
      "005160 already done\n",
      "005180 already done\n",
      "005250 already done\n",
      "005290 already done\n",
      "005300 already done\n",
      "005320 already done\n",
      "005360 already done\n",
      "005380 already done\n",
      "005390 already done\n",
      "005420 already done\n",
      "005430 already done\n",
      "005440 already done\n",
      "005490 already done\n",
      "005500 already done\n",
      "005610 already done\n",
      "005670 already done\n",
      "005680 already done\n",
      "005690 already done\n",
      "005710 already done\n",
      "005720 already done\n",
      "005740 already done\n",
      "005750 already done\n",
      "005800 already done\n",
      "005810 already done\n",
      "005820 already done\n",
      "005830 already done\n",
      "005850 already done\n",
      "005860 already done\n",
      "005870 already done\n",
      "005880 already done\n",
      "005930 already done\n",
      "005940 already done\n",
      "005950 already done\n",
      "005960 already done\n",
      "005990 already done\n",
      "006040 already done\n",
      "006050 already done\n",
      "006060 already done\n",
      "006090 already done\n",
      "006110 already done\n",
      "006120 already done\n",
      "006140 already done\n",
      "006200 already done\n",
      "006220 already done\n",
      "006260 already done\n",
      "006280 already done\n",
      "006340 already done\n",
      "006360 already done\n",
      "006370 already done\n",
      "006380 already done\n",
      "006390 already done\n",
      "006400 already done\n",
      "006490 already done\n",
      "006570 already done\n",
      "006620 already done\n",
      "006650 already done\n",
      "006660 already done\n",
      "006730 already done\n",
      "006740 already done\n",
      "006800 already done\n",
      "006840 already done\n",
      "006880 already done\n",
      "006890 already done\n",
      "006910 already done\n",
      "006920 already done\n",
      "006980 already done\n",
      "007070 already done\n",
      "007110 already done\n",
      "007120 already done\n",
      "007160 already done\n",
      "007210 already done\n",
      "007280 already done\n",
      "007310 already done\n",
      "007330 already done\n",
      "007340 already done\n",
      "007370 already done\n",
      "008350 already done\n",
      "008370 already done\n",
      "008420 already done\n",
      "008470 already done\n",
      "008490 already done\n",
      "008500 already done\n",
      "008600 already done\n",
      "008700 already done\n",
      "008730 already done\n",
      "008770 already done\n",
      "008830 already done\n",
      "008870 already done\n",
      "008930 already done\n",
      "008970 already done\n",
      "009070 already done\n",
      "009140 already done\n",
      "009150 already done\n",
      "009160 already done\n",
      "009180 already done\n",
      "009190 already done\n",
      "009200 already done\n",
      "009240 already done\n",
      "009270 already done\n",
      "009290 already done\n",
      "009300 already done\n",
      "009310 already done\n",
      "009320 already done\n",
      "009410 already done\n",
      "009420 already done\n",
      "009440 already done\n",
      "009450 already done\n",
      "009460 already done\n",
      "009470 already done\n",
      "009520 already done\n",
      "009580 already done\n",
      "009620 already done\n",
      "009680 already done\n",
      "009730 already done\n",
      "009770 already done\n",
      "009780 already done\n",
      "009810 already done\n",
      "009830 already done\n",
      "009900 already done\n",
      "009970 already done\n",
      "010040 already done\n",
      "010060 already done\n",
      "010100 already done\n",
      "010120 already done\n",
      "010130 already done\n",
      "010140 already done\n",
      "010170 already done\n",
      "010240 already done\n",
      "010280 already done\n",
      "010400 already done\n",
      "010420 already done\n",
      "010470 already done\n",
      "010580 already done\n",
      "010600 already done\n",
      "010620 already done\n",
      "010640 already done\n",
      "010660 already done\n",
      "010690 already done\n",
      "010770 already done\n",
      "010780 already done\n",
      "010820 already done\n",
      "010950 already done\n",
      "010960 already done\n",
      "011000 already done\n",
      "011040 already done\n",
      "011070 already done\n",
      "011080 already done\n",
      "011090 already done\n",
      "011150 already done\n",
      "011170 already done\n",
      "011200 already done\n",
      "011210 already done\n",
      "011230 already done\n",
      "011280 already done\n",
      "011300 already done\n",
      "011320 already done\n",
      "011330 already done\n",
      "011370 already done\n",
      "011390 already done\n",
      "011420 already done\n",
      "011500 already done\n",
      "011560 already done\n",
      "011690 already done\n",
      "011700 already done\n",
      "011760 already done\n",
      "011780 already done\n",
      "011790 already done\n",
      "011810 already done\n",
      "012030 already done\n",
      "012160 already done\n",
      "012170 already done\n",
      "012200 already done\n",
      "012280 already done\n",
      "012320 already done\n",
      "012330 already done\n",
      "012340 already done\n",
      "012450 already done\n",
      "012510 already done\n",
      "012600 already done\n",
      "012610 already done\n",
      "012620 already done\n",
      "012630 already done\n",
      "012690 already done\n",
      "012700 already done\n",
      "012750 already done\n",
      "012790 already done\n",
      "012800 already done\n",
      "012860 already done\n",
      "013000 already done\n",
      "013030 already done\n",
      "013120 already done\n",
      "013360 already done\n",
      "013520 already done\n",
      "013570 already done\n",
      "013580 already done\n",
      "013700 already done\n",
      "013720 already done\n",
      "013810 already done\n",
      "013870 already done\n",
      "013890 already done\n",
      "013990 already done\n",
      "014100 already done\n",
      "014130 already done\n",
      "014160 already done\n",
      "014190 already done\n",
      "014200 already done\n",
      "014280 already done\n",
      "014440 already done\n",
      "014470 already done\n",
      "014530 already done\n",
      "014570 already done\n",
      "014580 already done\n",
      "014620 already done\n",
      "014680 already done\n",
      "014710 already done\n",
      "014790 already done\n",
      "014820 already done\n",
      "014830 already done\n",
      "014910 already done\n",
      "014940 already done\n",
      "014970 already done\n",
      "014990 already done\n",
      "015020 already done\n",
      "015230 already done\n",
      "015260 already done\n",
      "015360 already done\n",
      "015590 already done\n",
      "015710 already done\n",
      "015750 already done\n",
      "015760 already done\n",
      "015860 already done\n",
      "015890 already done\n",
      "016090 already done\n",
      "016100 already done\n",
      "016250 already done\n",
      "016360 already done\n",
      "016380 already done\n",
      "016450 already done\n",
      "016580 already done\n",
      "016590 already done\n",
      "016600 already done\n",
      "016610 already done\n",
      "016670 already done\n",
      "016710 already done\n",
      "016740 already done\n",
      "016790 already done\n",
      "016800 already done\n",
      "016880 already done\n",
      "016920 already done\n",
      "017000 already done\n",
      "017040 already done\n",
      "017180 already done\n",
      "017250 already done\n",
      "017370 already done\n",
      "017390 already done\n",
      "017480 already done\n",
      "017510 already done\n",
      "017550 already done\n",
      "017650 already done\n",
      "017670 already done\n",
      "017800 already done\n",
      "017810 already done\n",
      "017890 already done\n",
      "017900 already done\n",
      "017940 already done\n",
      "017960 already done\n",
      "018000 already done\n",
      "018120 already done\n",
      "018250 already done\n",
      "018260 already done\n",
      "018290 already done\n",
      "018310 already done\n",
      "018470 already done\n",
      "018500 already done\n",
      "018620 already done\n",
      "018670 already done\n",
      "018680 already done\n",
      "018700 already done\n",
      "018880 already done\n",
      "019010 already done\n",
      "019170 already done\n",
      "019180 already done\n",
      "019210 already done\n",
      "019440 already done\n",
      "019490 already done\n",
      "019540 already done\n",
      "019550 already done\n",
      "019570 already done\n",
      "019590 already done\n",
      "019660 already done\n",
      "019680 already done\n",
      "019770 already done\n",
      "019990 already done\n",
      "020000 already done\n",
      "020150 already done\n",
      "020180 already done\n",
      "020400 already done\n",
      "020560 already done\n",
      "020710 already done\n",
      "020760 already done\n",
      "021040 already done\n",
      "021050 already done\n",
      "021080 already done\n",
      "021240 already done\n",
      "021320 already done\n",
      "021650 already done\n",
      "021820 already done\n",
      "021880 already done\n",
      "022100 already done\n",
      "022220 already done\n",
      "023000 already done\n",
      "023150 already done\n",
      "023160 already done\n",
      "023350 already done\n",
      "023410 already done\n",
      "023440 already done\n",
      "023450 already done\n",
      "023460 already done\n",
      "023530 already done\n",
      "023590 already done\n",
      "023600 already done\n",
      "023760 already done\n",
      "023770 already done\n",
      "023790 already done\n",
      "023800 already done\n",
      "023810 already done\n",
      "023900 already done\n",
      "023910 already done\n",
      "023960 already done\n",
      "024060 already done\n",
      "024070 already done\n",
      "024090 already done\n",
      "024110 already done\n",
      "024120 already done\n",
      "024720 already done\n",
      "024740 already done\n",
      "024800 already done\n",
      "024810 already done\n",
      "024830 already done\n",
      "024840 already done\n",
      "024850 already done\n",
      "024880 already done\n",
      "024890 already done\n",
      "024900 already done\n",
      "024910 already done\n",
      "024940 already done\n",
      "024950 already done\n",
      "025000 already done\n",
      "025320 already done\n",
      "025440 already done\n",
      "025530 already done\n",
      "025550 already done\n",
      "025750 already done\n",
      "025770 already done\n",
      "025820 already done\n",
      "025860 already done\n",
      "025870 already done\n",
      "025880 already done\n",
      "025890 already done\n",
      "025900 already done\n",
      "025950 already done\n",
      "025980 already done\n",
      "026040 already done\n",
      "026150 already done\n",
      "026890 already done\n",
      "026910 already done\n",
      "026940 already done\n",
      "026960 already done\n",
      "027040 already done\n",
      "027050 already done\n",
      "027360 already done\n",
      "027410 already done\n",
      "027580 already done\n",
      "027710 already done\n",
      "027740 already done\n",
      "027830 already done\n",
      "027970 already done\n",
      "028050 already done\n",
      "028080 already done\n",
      "028100 already done\n",
      "028260 already done\n",
      "028300 already done\n",
      "028670 already done\n",
      "029480 already done\n",
      "029530 already done\n",
      "029780 already done\n",
      "029960 already done\n",
      "030000 already done\n",
      "030190 already done\n",
      "030200 already done\n",
      "030210 already done\n",
      "030350 already done\n",
      "030520 already done\n",
      "030530 already done\n",
      "030610 already done\n",
      "030720 already done\n",
      "030960 already done\n",
      "031310 already done\n",
      "031330 already done\n",
      "031430 already done\n",
      "031440 already done\n",
      "031510 already done\n",
      "031820 already done\n",
      "031860 already done\n",
      "031980 already done\n",
      "032080 already done\n",
      "032190 already done\n",
      "032280 already done\n",
      "032300 already done\n",
      "032350 already done\n",
      "032500 already done\n",
      "032540 already done\n",
      "032560 already done\n",
      "032580 already done\n",
      "032620 already done\n",
      "032640 already done\n",
      "032680 already done\n",
      "032750 already done\n",
      "032830 already done\n",
      "032940 already done\n",
      "032960 already done\n",
      "032980 already done\n",
      "033050 already done\n",
      "033100 already done\n",
      "033130 already done\n",
      "033160 already done\n",
      "033170 already done\n",
      "033180 already done\n",
      "033200 already done\n",
      "033230 already done\n",
      "033240 already done\n",
      "033250 already done\n",
      "033270 already done\n",
      "033290 already done\n",
      "033310 already done\n",
      "033320 already done\n",
      "033340 already done\n",
      "033500 already done\n",
      "033530 already done\n",
      "033540 already done\n",
      "033560 already done\n",
      "033640 already done\n",
      "033780 already done\n",
      "033790 already done\n",
      "033830 already done\n",
      "033920 already done\n",
      "034020 already done\n",
      "034120 already done\n",
      "034220 already done\n",
      "034230 already done\n",
      "034300 already done\n",
      "034310 already done\n",
      "034590 already done\n",
      "034730 already done\n",
      "034810 already done\n",
      "034830 already done\n",
      "034940 already done\n",
      "034950 already done\n",
      "035000 already done\n",
      "035080 already done\n",
      "035150 already done\n",
      "035200 already done\n",
      "035250 already done\n",
      "035290 already done\n",
      "035420 already done\n",
      "035460 already done\n",
      "035510 already done\n",
      "035600 already done\n",
      "035610 already done\n",
      "035620 already done\n",
      "035720 already done\n",
      "035760 already done\n",
      "035810 already done\n",
      "035890 already done\n",
      "035900 already done\n",
      "036000 already done\n",
      "036010 already done\n",
      "036030 already done\n",
      "036090 already done\n",
      "036120 already done\n",
      "036170 already done\n",
      "036180 already done\n",
      "036190 already done\n",
      "036200 already done\n",
      "036220 already done\n",
      "036420 already done\n",
      "036460 already done\n",
      "036480 already done\n",
      "036530 already done\n",
      "036540 already done\n",
      "036560 already done\n",
      "036570 already done\n",
      "036580 already done\n",
      "036620 already done\n",
      "036630 already done\n",
      "036640 already done\n",
      "036670 already done\n",
      "036690 already done\n",
      "036710 already done\n",
      "036800 already done\n",
      "036810 already done\n",
      "036830 already done\n",
      "036890 already done\n",
      "036930 already done\n",
      "037070 already done\n",
      "037230 already done\n",
      "039610 already done\n",
      "039740 already done\n",
      "039830 already done\n",
      "039840 already done\n",
      "039860 already done\n",
      "039980 already done\n",
      "040160 already done\n",
      "040300 already done\n",
      "040350 already done\n",
      "040420 already done\n",
      "040610 already done\n",
      "040910 already done\n",
      "041020 already done\n",
      "041190 already done\n",
      "041440 already done\n",
      "041460 already done\n",
      "041510 already done\n",
      "041520 already done\n",
      "041590 already done\n",
      "041650 already done\n",
      "041830 already done\n",
      "041910 already done\n",
      "041920 already done\n",
      "041930 already done\n",
      "041960 already done\n",
      "042000 already done\n",
      "042040 already done\n",
      "042110 already done\n",
      "042370 already done\n",
      "042420 already done\n",
      "042500 already done\n",
      "042510 already done\n",
      "042520 already done\n",
      "042600 already done\n",
      "042660 already done\n",
      "042670 already done\n",
      "042700 already done\n",
      "042940 already done\n",
      "043090 already done\n",
      "043100 already done\n",
      "043150 already done\n",
      "043200 already done\n",
      "043220 already done\n",
      "043260 already done\n",
      "043340 already done\n",
      "043360 already done\n",
      "043370 already done\n",
      "043590 already done\n",
      "043610 already done\n",
      "043650 already done\n",
      "043710 already done\n",
      "043910 already done\n",
      "044060 already done\n",
      "044180 already done\n",
      "044340 already done\n",
      "044380 already done\n",
      "044450 already done\n",
      "044480 already done\n",
      "044490 already done\n",
      "044780 already done\n",
      "044960 already done\n",
      "045060 already done\n",
      "045100 already done\n",
      "045300 already done\n",
      "045340 already done\n",
      "045390 already done\n",
      "045510 already done\n",
      "045520 already done\n",
      "045660 already done\n",
      "045970 already done\n",
      "046070 already done\n",
      "046120 already done\n",
      "046210 already done\n",
      "046310 already done\n",
      "046390 already done\n",
      "046440 already done\n",
      "046890 already done\n",
      "046940 already done\n",
      "046970 already done\n",
      "047040 already done\n",
      "047050 already done\n",
      "047080 already done\n",
      "047310 already done\n",
      "047400 already done\n",
      "047560 already done\n",
      "047770 already done\n",
      "047810 already done\n",
      "047820 already done\n",
      "047920 already done\n",
      "048410 already done\n",
      "048430 already done\n",
      "048470 already done\n",
      "048530 already done\n",
      "048550 already done\n",
      "048770 already done\n",
      "048830 already done\n",
      "048870 already done\n",
      "048910 already done\n",
      "049070 already done\n",
      "049080 already done\n",
      "049120 already done\n",
      "049180 already done\n",
      "049430 already done\n",
      "049470 already done\n",
      "049480 already done\n",
      "049520 already done\n",
      "049550 already done\n",
      "049630 already done\n",
      "049720 already done\n",
      "049770 already done\n",
      "049800 already done\n",
      "049830 already done\n",
      "049950 already done\n",
      "049960 already done\n",
      "050090 already done\n",
      "050110 already done\n",
      "050120 already done\n",
      "050760 already done\n",
      "050860 already done\n",
      "050890 already done\n",
      "050960 already done\n",
      "051160 already done\n",
      "051360 already done\n",
      "051370 already done\n",
      "051380 already done\n",
      "051390 already done\n",
      "051490 already done\n",
      "051500 already done\n",
      "051600 already done\n",
      "051630 already done\n",
      "051780 already done\n",
      "051900 already done\n",
      "051910 already done\n",
      "051980 already done\n",
      "052020 already done\n",
      "052220 already done\n",
      "052260 already done\n",
      "052300 already done\n",
      "052330 already done\n",
      "052400 already done\n",
      "052420 already done\n",
      "052460 already done\n",
      "052600 already done\n",
      "052670 already done\n",
      "052690 already done\n",
      "052710 already done\n",
      "052770 already done\n",
      "052790 already done\n",
      "052860 already done\n",
      "052900 already done\n",
      "053030 already done\n",
      "053050 already done\n",
      "053060 already done\n",
      "053080 already done\n",
      "053160 already done\n",
      "053210 already done\n",
      "053260 already done\n",
      "053270 already done\n",
      "053280 already done\n",
      "053290 already done\n",
      "053300 already done\n",
      "053350 already done\n",
      "053450 already done\n",
      "053580 already done\n",
      "053590 already done\n",
      "053610 already done\n",
      "053620 already done\n",
      "053690 already done\n",
      "053700 already done\n",
      "053800 already done\n",
      "053950 already done\n",
      "053980 already done\n",
      "054040 already done\n",
      "054050 already done\n",
      "054090 already done\n",
      "054180 already done\n",
      "054210 already done\n",
      "054220 already done\n",
      "054300 already done\n",
      "054410 already done\n",
      "054450 already done\n",
      "054540 already done\n",
      "054620 already done\n",
      "054630 already done\n",
      "054670 already done\n",
      "054780 already done\n",
      "054800 already done\n",
      "054920 already done\n",
      "054930 already done\n",
      "054940 already done\n",
      "054950 already done\n",
      "055490 already done\n",
      "055550 already done\n",
      "056080 already done\n",
      "056090 already done\n",
      "056190 already done\n",
      "056360 already done\n",
      "056700 already done\n",
      "056730 already done\n",
      "057030 already done\n",
      "057050 already done\n",
      "057540 already done\n",
      "057680 already done\n",
      "057880 already done\n",
      "058110 already done\n",
      "058400 already done\n",
      "058430 already done\n",
      "058450 already done\n",
      "058470 already done\n",
      "058610 already done\n",
      "058630 already done\n",
      "058650 already done\n",
      "058730 already done\n",
      "058820 already done\n",
      "058850 already done\n",
      "058860 already done\n",
      "058970 already done\n",
      "059090 already done\n",
      "059100 already done\n",
      "059120 already done\n",
      "059210 already done\n",
      "059270 already done\n",
      "060150 already done\n",
      "060230 already done\n",
      "060240 already done\n",
      "060250 already done\n",
      "060260 already done\n",
      "060280 already done\n",
      "060310 already done\n",
      "060370 already done\n",
      "060380 already done\n",
      "060480 already done\n",
      "060540 already done\n",
      "060560 already done\n",
      "060570 already done\n",
      "060590 already done\n",
      "060720 already done\n",
      "060850 already done\n",
      "060900 already done\n",
      "060980 already done\n",
      "061040 already done\n",
      "061250 already done\n",
      "061970 already done\n",
      "062860 already done\n",
      "062970 already done\n",
      "063080 already done\n",
      "063160 already done\n",
      "063170 already done\n",
      "063440 already done\n",
      "063570 already done\n",
      "063760 already done\n",
      "064090 already done\n",
      "064240 already done\n",
      "064260 already done\n",
      "064290 already done\n",
      "064350 already done\n",
      "064480 already done\n",
      "064520 already done\n",
      "064550 already done\n",
      "064760 already done\n",
      "064800 already done\n",
      "064820 already done\n",
      "064850 already done\n",
      "064960 already done\n",
      "065060 already done\n",
      "065130 already done\n",
      "065150 already done\n",
      "065170 already done\n",
      "065350 already done\n",
      "065370 already done\n",
      "065420 already done\n",
      "065440 already done\n",
      "065450 already done\n",
      "065500 already done\n",
      "065510 already done\n",
      "065530 already done\n",
      "065560 already done\n",
      "065570 already done\n",
      "065650 already done\n",
      "065660 already done\n",
      "065680 already done\n",
      "065690 already done\n",
      "065710 already done\n",
      "065770 already done\n",
      "065950 already done\n",
      "066130 already done\n",
      "066310 already done\n",
      "066360 already done\n",
      "066410 already done\n",
      "066430 already done\n",
      "066570 already done\n",
      "066590 already done\n",
      "066620 already done\n",
      "066670 already done\n",
      "066700 already done\n",
      "066790 already done\n",
      "066900 already done\n",
      "066910 already done\n",
      "066970 already done\n",
      "066980 already done\n",
      "067000 already done\n",
      "067010 already done\n",
      "067080 already done\n",
      "067160 already done\n",
      "067170 already done\n",
      "067280 already done\n",
      "067290 already done\n",
      "067310 already done\n",
      "067370 already done\n",
      "067390 already done\n",
      "067570 already done\n",
      "067630 already done\n",
      "067730 already done\n",
      "067770 already done\n",
      "067830 already done\n",
      "067900 already done\n",
      "067920 already done\n",
      "067990 already done\n",
      "068050 already done\n",
      "068240 already done\n",
      "068270 already done\n",
      "068290 already done\n",
      "068330 already done\n",
      "068760 already done\n",
      "068790 already done\n",
      "068930 already done\n",
      "068940 already done\n",
      "069080 already done\n",
      "069140 already done\n",
      "069260 already done\n",
      "069330 already done\n",
      "069410 already done\n",
      "069460 already done\n",
      "069510 already done\n",
      "069540 already done\n",
      "069620 already done\n",
      "069640 already done\n",
      "069730 already done\n",
      "069920 already done\n",
      "069960 already done\n",
      "070300 already done\n",
      "070590 already done\n",
      "070960 already done\n",
      "071050 already done\n",
      "071090 already done\n",
      "071200 already done\n",
      "071280 already done\n",
      "071320 already done\n",
      "071460 already done\n",
      "071670 already done\n",
      "071840 already done\n",
      "071850 already done\n",
      "071950 already done\n",
      "071970 already done\n",
      "072020 already done\n",
      "072130 already done\n",
      "072470 already done\n",
      "072520 already done\n",
      "072710 already done\n",
      "072770 already done\n",
      "072870 already done\n",
      "072950 already done\n",
      "072990 already done\n",
      "073010 already done\n",
      "073110 already done\n",
      "073190 already done\n",
      "073240 already done\n",
      "073490 already done\n",
      "073540 already done\n",
      "073560 already done\n",
      "073570 already done\n",
      "073640 already done\n",
      "074430 already done\n",
      "074600 already done\n",
      "074610 already done\n",
      "075130 already done\n",
      "075180 already done\n",
      "075580 already done\n",
      "075970 already done\n",
      "076080 already done\n",
      "076610 already done\n",
      "077360 already done\n",
      "077500 already done\n",
      "077970 already done\n",
      "078000 already done\n",
      "078020 already done\n",
      "078070 already done\n",
      "078130 already done\n",
      "078140 already done\n",
      "078150 already done\n",
      "078160 already done\n",
      "078340 already done\n",
      "078350 already done\n",
      "078520 already done\n",
      "078590 already done\n",
      "078600 already done\n",
      "078860 already done\n",
      "078890 already done\n",
      "078930 already done\n",
      "078940 already done\n",
      "079000 already done\n",
      "079160 already done\n",
      "079170 already done\n",
      "079190 already done\n",
      "079370 already done\n",
      "079430 already done\n",
      "079550 already done\n",
      "079650 already done\n",
      "079810 already done\n",
      "079940 already done\n",
      "079950 already done\n",
      "079960 already done\n",
      "079970 already done\n",
      "079980 already done\n",
      "080000 already done\n",
      "080010 already done\n",
      "080160 already done\n",
      "080220 already done\n",
      "080420 already done\n",
      "080470 already done\n",
      "080520 already done\n",
      "080530 already done\n",
      "080580 already done\n",
      "080720 already done\n",
      "081000 already done\n",
      "081150 already done\n",
      "081580 already done\n",
      "081660 already done\n",
      "082210 already done\n",
      "082270 already done\n",
      "082640 already done\n",
      "082660 already done\n",
      "082740 already done\n",
      "082800 already done\n",
      "082850 already done\n",
      "082920 already done\n",
      "083310 already done\n",
      "083420 already done\n",
      "083450 already done\n",
      "083470 already done\n",
      "083500 already done\n",
      "083550 already done\n",
      "083640 already done\n",
      "083650 already done\n",
      "083660 already done\n",
      "083790 already done\n",
      "083930 already done\n",
      "084010 already done\n",
      "084110 already done\n",
      "084180 already done\n",
      "084370 already done\n",
      "084440 already done\n",
      "084650 already done\n",
      "084670 already done\n",
      "084680 already done\n",
      "084690 already done\n",
      "084730 already done\n",
      "084850 already done\n",
      "084870 already done\n",
      "084990 already done\n",
      "085310 already done\n",
      "085620 already done\n",
      "085660 already done\n",
      "085670 already done\n",
      "085810 already done\n",
      "085910 already done\n",
      "086040 already done\n",
      "086060 already done\n",
      "086280 already done\n",
      "086390 already done\n",
      "086450 already done\n",
      "086520 already done\n",
      "086670 already done\n",
      "086710 already done\n",
      "086790 already done\n",
      "086820 already done\n",
      "086890 already done\n",
      "086900 already done\n",
      "086960 already done\n",
      "086980 already done\n",
      "087010 already done\n",
      "089030 already done\n",
      "090710 already done\n",
      "090850 already done\n",
      "091090 already done\n",
      "091120 already done\n",
      "091340 already done\n",
      "091440 already done\n",
      "091580 already done\n",
      "091590 already done\n",
      "091700 already done\n",
      "091810 already done\n",
      "091970 already done\n",
      "092040 already done\n",
      "092070 already done\n",
      "092130 already done\n",
      "092190 already done\n",
      "092200 already done\n",
      "092220 already done\n",
      "092230 already done\n",
      "092300 already done\n",
      "092440 already done\n",
      "092460 already done\n",
      "092600 already done\n",
      "092730 already done\n",
      "092780 already done\n",
      "092870 already done\n",
      "093050 already done\n",
      "093190 already done\n",
      "093230 already done\n",
      "093240 already done\n",
      "093320 already done\n",
      "093370 already done\n",
      "093380 already done\n",
      "093520 already done\n",
      "093640 already done\n",
      "093920 already done\n",
      "094170 already done\n",
      "094280 already done\n",
      "094360 already done\n",
      "094480 already done\n",
      "094820 already done\n",
      "094840 already done\n",
      "094850 already done\n",
      "094860 already done\n",
      "094940 already done\n",
      "094970 already done\n",
      "095190 already done\n",
      "095270 already done\n",
      "095340 already done\n",
      "095500 already done\n",
      "095570 already done\n",
      "095610 already done\n",
      "095660 already done\n",
      "095700 already done\n",
      "095720 already done\n",
      "095910 already done\n",
      "096040 already done\n",
      "096240 already done\n",
      "096350 already done\n",
      "096530 already done\n",
      "096610 already done\n",
      "096630 already done\n",
      "096690 already done\n",
      "096760 already done\n",
      "096770 already done\n",
      "096870 already done\n",
      "097230 already done\n",
      "097520 already done\n",
      "097780 already done\n",
      "097800 already done\n",
      "097870 already done\n",
      "097950 already done\n",
      "098120 already done\n",
      "098460 already done\n",
      "098660 already done\n",
      "099190 already done\n",
      "099220 already done\n",
      "099320 already done\n",
      "099390 already done\n",
      "099410 already done\n",
      "099430 already done\n",
      "099440 already done\n",
      "099520 already done\n",
      "099750 already done\n",
      "100030 already done\n",
      "100090 already done\n",
      "100120 already done\n",
      "100130 already done\n",
      "100220 already done\n",
      "100250 already done\n",
      "100590 already done\n",
      "100660 already done\n",
      "100700 already done\n",
      "100790 already done\n",
      "100840 already done\n",
      "101000 already done\n",
      "101140 already done\n",
      "101160 already done\n",
      "101170 already done\n",
      "101240 already done\n",
      "101330 already done\n",
      "101360 already done\n",
      "101390 already done\n",
      "101400 already done\n",
      "101490 already done\n",
      "101530 already done\n",
      "101670 already done\n",
      "101680 already done\n",
      "101730 already done\n",
      "101930 already done\n",
      "102120 already done\n",
      "102260 already done\n",
      "102280 already done\n",
      "102370 already done\n",
      "102460 already done\n",
      "102710 already done\n",
      "102940 already done\n",
      "103140 already done\n",
      "103230 already done\n",
      "103590 already done\n",
      "103840 already done\n",
      "104040 already done\n",
      "104200 already done\n",
      "104460 already done\n",
      "104480 already done\n",
      "104540 already done\n",
      "104620 already done\n",
      "104700 already done\n",
      "104830 already done\n",
      "105330 already done\n",
      "105550 already done\n",
      "105560 already done\n",
      "105630 already done\n",
      "105740 already done\n",
      "105840 already done\n",
      "106080 already done\n",
      "106190 already done\n",
      "106240 already done\n",
      "106520 already done\n",
      "107590 already done\n",
      "107600 already done\n",
      "107640 already done\n",
      "108230 already done\n",
      "108320 already done\n",
      "108380 already done\n",
      "108490 already done\n",
      "108670 already done\n",
      "108860 already done\n",
      "109070 already done\n",
      "109080 already done\n",
      "109610 already done\n",
      "109740 already done\n",
      "109820 already done\n",
      "109860 already done\n",
      "109960 already done\n",
      "110020 already done\n",
      "110790 already done\n",
      "110990 already done\n",
      "111110 already done\n",
      "111710 already done\n",
      "111770 already done\n",
      "111870 already done\n",
      "112040 already done\n",
      "112290 already done\n",
      "112610 already done\n",
      "113810 already done\n",
      "114090 already done\n",
      "114190 already done\n",
      "114450 already done\n",
      "114630 already done\n",
      "114810 already done\n",
      "114840 already done\n",
      "115160 already done\n",
      "115180 already done\n",
      "115310 already done\n",
      "115390 already done\n",
      "115440 already done\n",
      "115450 already done\n",
      "115480 already done\n",
      "115500 already done\n",
      "115530 already done\n",
      "115570 already done\n",
      "115610 already done\n",
      "117580 already done\n",
      "117670 already done\n",
      "117730 already done\n",
      "118000 already done\n",
      "118990 already done\n",
      "119500 already done\n",
      "119610 already done\n",
      "119650 already done\n",
      "119830 already done\n",
      "119850 already done\n",
      "119860 already done\n",
      "120030 already done\n",
      "120110 already done\n",
      "120240 already done\n",
      "121440 already done\n",
      "121600 already done\n",
      "121800 already done\n",
      "121850 already done\n",
      "121890 already done\n",
      "122310 already done\n",
      "122350 already done\n",
      "122450 already done\n",
      "122640 already done\n",
      "122690 already done\n",
      "122870 already done\n",
      "122900 already done\n",
      "122990 already done\n",
      "123010 already done\n",
      "123040 already done\n",
      "123330 already done\n",
      "123410 already done\n",
      "123420 already done\n",
      "123570 already done\n",
      "123690 already done\n",
      "123700 already done\n",
      "123750 already done\n",
      "123840 already done\n",
      "123860 already done\n",
      "123890 already done\n",
      "124500 already done\n",
      "124560 already done\n",
      "125210 already done\n",
      "126340 already done\n",
      "126560 already done\n",
      "126600 already done\n",
      "126640 already done\n",
      "126700 already done\n",
      "126720 already done\n",
      "126880 already done\n",
      "127120 already done\n",
      "127710 already done\n",
      "127980 already done\n",
      "128540 already done\n",
      "128660 already done\n",
      "128820 already done\n",
      "128940 already done\n",
      "129260 already done\n",
      "129890 already done\n",
      "129920 already done\n",
      "130500 already done\n",
      "130580 already done\n",
      "130660 already done\n",
      "130740 already done\n",
      "131030 already done\n",
      "131090 already done\n",
      "131100 already done\n",
      "131180 already done\n",
      "131220 already done\n",
      "131290 already done\n",
      "131370 already done\n",
      "131400 already done\n",
      "131760 already done\n",
      "131970 already done\n",
      "133750 already done\n",
      "133820 already done\n",
      "134060 already done\n",
      "134380 already done\n",
      "134580 already done\n",
      "134790 already done\n",
      "136410 already done\n",
      "136480 already done\n",
      "136490 already done\n",
      "136510 already done\n",
      "136540 already done\n",
      "137080 already done\n",
      "137310 already done\n",
      "137400 already done\n",
      "137940 already done\n",
      "137950 already done\n",
      "138040 already done\n",
      "138070 already done\n",
      "138080 already done\n",
      "138360 already done\n",
      "138490 already done\n",
      "138580 already done\n",
      "138610 already done\n",
      "138930 already done\n",
      "139050 already done\n",
      "139130 already done\n",
      "139480 already done\n",
      "139670 already done\n",
      "139990 already done\n",
      "140070 already done\n",
      "140410 already done\n",
      "140520 already done\n",
      "140670 already done\n",
      "140860 already done\n",
      "141000 already done\n",
      "141080 already done\n",
      "142210 already done\n",
      "142280 already done\n",
      "142760 already done\n",
      "143160 already done\n",
      "143210 already done\n",
      "143240 already done\n",
      "143540 already done\n",
      "144510 already done\n",
      "144960 already done\n",
      "145020 already done\n",
      "145210 already done\n",
      "145720 already done\n",
      "145990 already done\n",
      "146320 already done\n",
      "147760 already done\n",
      "147830 already done\n",
      "148150 already done\n",
      "148250 already done\n",
      "148780 already done\n",
      "148930 already done\n",
      "149950 already done\n",
      "149980 already done\n",
      "150840 already done\n",
      "150900 already done\n",
      "151860 already done\n",
      "151910 already done\n",
      "153460 already done\n",
      "153490 already done\n",
      "153710 already done\n",
      "154030 already done\n",
      "154040 already done\n",
      "155650 already done\n",
      "155660 already done\n",
      "156100 already done\n",
      "158430 already done\n",
      "159010 already done\n",
      "159580 already done\n",
      "159910 already done\n",
      "160550 already done\n",
      "160600 already done\n",
      "160980 already done\n",
      "161000 already done\n",
      "161390 already done\n",
      "161580 already done\n",
      "161890 already done\n",
      "162300 already done\n",
      "163560 already done\n",
      "163730 already done\n",
      "164060 already done\n",
      "166090 already done\n",
      "166480 already done\n",
      "168330 already done\n",
      "168360 already done\n",
      "169330 already done\n",
      "170030 already done\n",
      "170790 already done\n",
      "170900 already done\n",
      "170920 already done\n",
      "171010 already done\n",
      "171090 already done\n",
      "171120 already done\n",
      "173130 already done\n",
      "173940 already done\n",
      "174880 already done\n",
      "174900 already done\n",
      "175140 already done\n",
      "175250 already done\n",
      "175330 already done\n",
      "177350 already done\n",
      "177830 already done\n",
      "178320 already done\n",
      "178780 already done\n",
      "178920 already done\n",
      "179290 already done\n",
      "179530 already done\n",
      "179900 already done\n",
      "180400 already done\n",
      "180640 already done\n",
      "181340 already done\n",
      "181710 already done\n",
      "182360 already done\n",
      "182400 already done\n",
      "183190 already done\n",
      "183300 already done\n",
      "183490 already done\n",
      "184230 already done\n",
      "185490 already done\n",
      "185750 already done\n",
      "186230 already done\n",
      "187220 already done\n",
      "187270 already done\n",
      "187420 already done\n",
      "187660 already done\n",
      "187790 already done\n",
      "187870 already done\n",
      "189300 already done\n",
      "189330 already done\n",
      "189690 already done\n",
      "189860 already done\n",
      "189980 already done\n",
      "190510 already done\n",
      "190650 already done\n",
      "191410 already done\n",
      "191420 already done\n",
      "192080 already done\n",
      "192250 already done\n",
      "192390 already done\n",
      "192400 already done\n",
      "192410 already done\n",
      "192440 already done\n",
      "192650 already done\n",
      "192820 already done\n",
      "193250 already done\n",
      "194370 already done\n",
      "194480 already done\n",
      "194700 already done\n",
      "195500 already done\n",
      "195870 already done\n",
      "195940 already done\n",
      "195990 already done\n",
      "196170 already done\n",
      "196300 already done\n",
      "196450 already done\n",
      "196490 already done\n",
      "196700 already done\n",
      "197140 already done\n",
      "198080 already done\n",
      "198440 already done\n",
      "198940 already done\n",
      "199730 already done\n",
      "199800 already done\n",
      "199820 already done\n",
      "200130 already done\n",
      "200230 already done\n",
      "200350 already done\n",
      "200470 already done\n",
      "200670 already done\n",
      "200710 already done\n",
      "200780 already done\n",
      "200880 already done\n",
      "201490 already done\n",
      "203400 already done\n",
      "203450 already done\n",
      "203650 already done\n",
      "203690 already done\n",
      "204020 already done\n",
      "204270 already done\n",
      "204320 already done\n",
      "204610 already done\n",
      "204620 already done\n",
      "204630 already done\n",
      "204840 already done\n",
      "205100 already done\n",
      "205470 already done\n",
      "205500 already done\n",
      "206400 already done\n",
      "206560 already done\n",
      "206640 already done\n",
      "206650 already done\n",
      "207760 already done\n",
      "207940 already done\n",
      "208140 already done\n",
      "208340 데이터베이스에 저장 완료\n",
      "208350 데이터베이스에 저장 완료\n",
      "208370 데이터베이스에 저장 완료\n",
      "208640 데이터베이스에 저장 완료\n",
      "208710 데이터베이스에 저장 완료\n",
      "208860 데이터베이스에 저장 완료\n",
      "208870 skipped because it called 하나머스트3호스팩\n",
      "210120 데이터베이스에 저장 완료\n",
      "210540 데이터베이스에 저장 완료\n",
      "210980 데이터베이스에 저장 완료\n",
      "211050 데이터베이스에 저장 완료\n",
      "211270 데이터베이스에 저장 완료\n",
      "212560 데이터베이스에 저장 완료\n",
      "1037 days 12:22:56.632677 2024-08-03 12:22:56.632677 2021-10-01 00:00:00\n",
      "213090 데이터베이스에 저장 완료\n",
      "213420 데이터베이스에 저장 완료\n",
      "213500 데이터베이스에 저장 완료\n",
      "214150 데이터베이스에 저장 완료\n",
      "214180 데이터베이스에 저장 완료\n",
      "214260 데이터베이스에 저장 완료\n",
      "214270 데이터베이스에 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pymysql\n",
    "import configparser\n",
    "from pykrx import stock\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "# 대기 시간 설정 함수\n",
    "def random_sleep(min_seconds=6, max_seconds=11):\n",
    "    time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "    \n",
    "\"\"\"\n",
    "# 설정 파일 읽기\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "username = config['mysql']['username']\n",
    "password = config['mysql']['password']\n",
    "host = config['mysql']['host']\n",
    "database = config['mysql']['database']\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ConfigParser 객체 생성\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# config.ini 파일 경로 설정\n",
    "config_file_path = 'E:\\\\AI\\\\pythonProject\\\\venv\\\\masicsplit\\\\config.ini'\n",
    "\n",
    "# 경로가 올바른지 확인\n",
    "if os.path.exists(config_file_path):\n",
    "    print(\"config.ini 파일을 찾았습니다.\")\n",
    "    config.read(config_file_path)\n",
    "else:\n",
    "    print(\"config.ini 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "\n",
    "# mysql 섹션에서 설정값 가져오기\n",
    "try:\n",
    "    username = config['mysql']['user']\n",
    "    password = config['mysql']['password']\n",
    "    host = config['mysql']['host']\n",
    "    database=config['mysql']['database']\n",
    "    print(f\"Username: {username}, Password: {password}, Host: {host}\")\n",
    "except KeyError as e:\n",
    "    print(f\"설정 파일에서 키를 찾을 수 없습니다: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"기타 오류 발생: {e}\")\n",
    "    \n",
    "    \n",
    "conn = pymysql.connect(host=host, user=username, password=password, db=database, charset='utf8')\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 조건 설정\n",
    "per_threshold = 100\n",
    "pbr_threshold = 10\n",
    "div_threshold = 0  # 기준금리 참조\n",
    "\n",
    "# 현재 날짜 기준으로 최근 월 종목 리스트 수집\n",
    "current_date = datetime.datetime.now()\n",
    "last_month_str = current_date.strftime(\"%Y%m\") + '01'\n",
    "\n",
    "# 데이터베이스에서 모든 티커 가져오기\n",
    "cur.execute(\"SELECT ticker FROM ticker_list\")\n",
    "all_tickers = [row[0] for row in cur.fetchall()]\n",
    "\n",
    "# 각 티커에 대한 처리\n",
    "for ticker in all_tickers:\n",
    "    # 이미 처리된 티커는 스킵\n",
    "    cur.execute(f\"SELECT status FROM ticker_status WHERE ticker = '{ticker}'\")\n",
    "    status = cur.fetchone()\n",
    "    if status and status[0] == 'completed':\n",
    "        continue\n",
    "    \n",
    "     # 티커의 끝자리가 0이 아닌 경우 스킵\n",
    "    if ticker[-1] != '0':\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} skipped because it does not end with 0')\n",
    "        continue \n",
    "       \n",
    "   \n",
    "    # 데이터베이스에서 마지막 날짜 확인\n",
    "    cur.execute(f\"SELECT MAX(date) FROM stock_data WHERE ticker = '{ticker}'\")\n",
    "    last_date = cur.fetchone()[0]\n",
    "    # 마지막 날짜가 현재 날짜와 7일 이하로 차이나는 경우 continue\n",
    "    if last_date: # 이미 저장된 데이터가 있다면\n",
    "        last_recorded_date = pd.to_datetime(last_date)\n",
    "        if (current_date - last_recorded_date).days <= 30:\n",
    "            print(f'{ticker} already done')\n",
    "            continue\n",
    "    random_sleep()\n",
    "    name = stock.get_market_ticker_name(ticker)\n",
    "    if \"스팩\" in name:\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} skipped because it called {name}')\n",
    "        continue\n",
    "    # 새 데이터를 가져옴\n",
    "    if last_date:\n",
    "        start_date = (last_date + datetime.timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    else:\n",
    "        start_date = \"19800102\"\n",
    "    \n",
    "    end_date = current_date.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    random_sleep()\n",
    "    df2 = stock.get_market_fundamental(start_date, end_date, ticker)\n",
    "    if df2.empty or 'PER' not in df2.columns:\n",
    "    \n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "    \n",
    "        print(f'{ticker} no.2 pass condition')\n",
    "        random_sleep()\n",
    "        continue\n",
    "    '''\n",
    "    # 조건 확인\n",
    "    if ('PER' in df2.columns and 'PBR' in df2.columns and 'DIV' in df2.columns):\n",
    "        condition = (df2['PER'] > 0) & (df2['PER'] <= per_threshold) & \\\n",
    "                    (df2['PBR'] > 0) & (df2['PBR'] <= pbr_threshold) & \\\n",
    "                    (df2['DIV'] >= div_threshold)\n",
    "        if not condition.any() and last_date is None:  #조건을 만족하지 않거나 새로운데이터가 없으면 해당 종목은 종료(completed)\n",
    "            cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "            conn.commit()\n",
    "            print(f'{ticker} no.3 pass condition')\n",
    "            time.sleep(5.5)  \n",
    "            continue  # 조건을 만족하지 않으면 다음 티커로 넘어감\n",
    "        \n",
    "    else:\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} no.4 pass condition')\n",
    "        continue  # 필요한 컬럼이 없으면 넘어감\n",
    "    '''        \n",
    "    random_sleep()\n",
    "    df1 = stock.get_market_ohlcv(start_date, end_date, ticker)\n",
    "    \n",
    "\n",
    "    if df1.empty:\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} no.5 pass condition')\n",
    "        random_sleep()\n",
    "        continue\n",
    "\n",
    "    # '고가' 컬럼이 있는지 확인\n",
    "    if '고가' not in df1.columns:\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} no.6 pass condition')\n",
    "        random_sleep()\n",
    "        continue\n",
    "    random_sleep()\n",
    "    df3 = stock.get_market_cap(start_date, end_date, ticker)\n",
    "    \n",
    "    \n",
    "    df1.reset_index(inplace=True)\n",
    "    df2.reset_index(inplace=True)\n",
    "    df3.reset_index(inplace=True)\n",
    "    # 컬럼명 통일\n",
    "    df1.rename(columns={\n",
    "        '날짜': 'date',\n",
    "        '시가': 'open',\n",
    "        '고가': 'high',\n",
    "        '저가': 'low',\n",
    "        '종가': 'close',\n",
    "        '거래량': 'volume',\n",
    "        \n",
    "    }, inplace=True)\n",
    "\n",
    "    df2.rename(columns={\n",
    "        '날짜': 'date',\n",
    "        'PER': 'PER',\n",
    "        'PBR': 'PBR',\n",
    "        'DIV': 'dividend',\n",
    "        'BPS': 'BPS',\n",
    "        'EPS': 'EPS',\n",
    "        'DPS': 'DPS'\n",
    "    }, inplace=True)\n",
    "\n",
    "    df3.rename(columns={\n",
    "        '날짜': 'date',\n",
    "        '시가총액': 'market_cap',\n",
    "        '상장주식수': 'shares_outstanding',\n",
    "        '거래대금': 'value',\n",
    "        '거래량': 'volume'\n",
    "        \n",
    "    }, inplace=True)\n",
    "\n",
    "    \n",
    "     # 날짜 기준으로 결합하고 중복된 열 제거\n",
    "    merged_df = pd.merge(df1, df2, on='date', how='outer', suffixes=('', '_duplicate'))\n",
    "    merged_df = pd.merge(merged_df, df3, on='date', how='left', suffixes=('', '_duplicate'))\n",
    "    \n",
    "    # 중복된 열 제거\n",
    "    for column in merged_df.columns:\n",
    "        if 'duplicate' in column:\n",
    "            base_column = column.replace('_duplicate', '')\n",
    "            if base_column in merged_df.columns:\n",
    "                merged_df.drop(column, axis=1, inplace=True)\n",
    "    \n",
    "    # 필요한 열만 남기기\n",
    "    merged_df = merged_df[['date', 'open', 'high', 'low', 'close', 'volume', 'value', 'market_cap', 'shares_outstanding', 'PER', 'PBR', 'dividend', 'BPS', 'EPS', 'DPS']]\n",
    "    # merged_df 상태 출력\n",
    "  \n",
    "    # NaN 값을 None으로 변환 (개별적으로 처리)\n",
    "    merged_df = merged_df.replace({np.nan: None})\n",
    "    # # merged_df 상태 출력\n",
    "    # print(\"merged_df:\")\n",
    "    # print(merged_df.head())\n",
    "\n",
    "    merged_df['ticker'] = ticker\n",
    "    merged_df['name'] = name\n",
    "  \n",
    "    \n",
    "\n",
    "    # 기존 데이터를 가져와서 새로운 데이터와 결합\n",
    "    if last_date:\n",
    "        cur.execute(f\"SELECT * FROM stock_data WHERE ticker = '{ticker}' AND date <= '{last_date}'\")\n",
    "        existing_data = pd.DataFrame(cur.fetchall(), columns=['ticker', 'name', 'date', 'open', 'high', 'low', 'close', 'volume', 'value', 'market_cap', 'shares_outstanding', 'PER', 'PBR', 'dividend', 'BPS', 'EPS', 'DPS','normalized_value'])\n",
    "        existing_data['date'] = pd.to_datetime(existing_data['date'])\n",
    "        existing_data.set_index('date', inplace=True)\n",
    "        merged_df.set_index('date', inplace=True)\n",
    "        combined_df = pd.concat([existing_data, merged_df], axis=0, join='outer')\n",
    "          # 여기서 결합 전에 각 데이터프레임 확인\n",
    "\n",
    "        \n",
    "    else: # 기존데이터가 없으면 로드된 세 DF만 결합\n",
    "        combined_df = merged_df\n",
    "    # print(combined_df)\n",
    "        \n",
    "        \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    combined_df['min_close'] = combined_df['close'].rolling(window=252*5, min_periods=252).min()\n",
    "    combined_df['max_close'] = combined_df['close'].rolling(window=252*5, min_periods=252).max()\n",
    "\n",
    "    # 각 행에 대해 'min_close'와 'max_close'가 0이 아닌지 확인하여 'normalized_value' 계산\n",
    "    def calculate_normalized_value(row):\n",
    "        if pd.notnull(row['min_close']) and pd.notnull(row['max_close']) and (row['max_close'] - row['min_close']) != 0:\n",
    "            return (row['close'] - row['min_close']) / (row['max_close'] - row['min_close']) * 100\n",
    "        else:\n",
    "            return None\n",
    "    try:\n",
    "        combined_df['normalized_value'] = combined_df.apply(calculate_normalized_value, axis=1)\n",
    "    except TypeError as e:\n",
    "        print(f\"TypeError encountered: {e}\")\n",
    "        \n",
    "        print(f'{ticker} no.7 pass condition')\n",
    "        continue\n",
    "\n",
    "    if combined_df['normalized_value'].isnull().all():\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} no.8 pass condition')\n",
    "        continue\n",
    "\n",
    "\n",
    "    combined_df.reset_index(inplace=True)\n",
    "    \n",
    "    combined_df = combined_df.replace({np.nan: None})\n",
    "    \n",
    "\n",
    "    # 데이터베이스에 저장\n",
    "    for _, row in combined_df.iterrows():\n",
    "        sql = '''\n",
    "        INSERT INTO stock_data (ticker, name, date, open, high, low, close, volume, value, market_cap, shares_outstanding, PER, PBR, dividend, BPS, EPS, DPS, normalized_value)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ON DUPLICATE KEY UPDATE\n",
    "            open=VALUES(open),\n",
    "            high=VALUES(high),\n",
    "            low=VALUES(low),\n",
    "            close=VALUES(close),\n",
    "            volume=VALUES(volume),\n",
    "            value=VALUES(value),\n",
    "            market_cap=VALUES(market_cap),\n",
    "            shares_outstanding=VALUES(shares_outstanding),\n",
    "            PER=VALUES(PER),\n",
    "            PBR=VALUES(PBR),\n",
    "            dividend=VALUES(dividend),\n",
    "            BPS=VALUES(BPS),\n",
    "            EPS=VALUES(EPS),\n",
    "            DPS=VALUES(DPS),\n",
    "            normalized_value=VALUES(normalized_value)\n",
    "        '''\n",
    "        cur.execute(sql, (\n",
    "            row['ticker'],\n",
    "            row['name'],\n",
    "            row['date'].strftime('%Y-%m-%d') if row['date'] else None,\n",
    "            row['open'],\n",
    "            row['high'],\n",
    "            row['low'],\n",
    "            row['close'],\n",
    "            int(row['volume']) if row['volume'] is not None else None,\n",
    "            int(row['value']) if row['value'] is not None else None,\n",
    "            int(row['market_cap']) if row['market_cap'] is not None else None,\n",
    "            int(row['shares_outstanding']) if row['shares_outstanding'] is not None else None,\n",
    "            row['PER'],\n",
    "            row['PBR'],\n",
    "            row['dividend'],\n",
    "            row['BPS'],\n",
    "            row['EPS'],\n",
    "            row['DPS'],\n",
    "            row['normalized_value']\n",
    "        ))\n",
    "\n",
    "    conn.commit()\n",
    "     # 최근 60일 동안 데이터가 있는지 확인\n",
    "    last_recorded_date = pd.to_datetime(combined_df['date']).max()\n",
    "    if (current_date - last_recorded_date).days > 60:\n",
    "        print(current_date - last_recorded_date,current_date,last_recorded_date)\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "    print(f\"{ticker} 데이터베이스에 저장 완료\")\n",
    "    random_sleep()  \n",
    "\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"모든 데이터가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "591f446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.ini 파일을 찾았습니다.\n",
      "Username: root, Password: @waren2ss, Host: 127.0.0.1\n",
      "None 19800102 20240803\n",
      "             BPS    PER   PBR  EPS  DIV  DPS\n",
      "날짜                                          \n",
      "2018-09-07  5085  13.71  2.14  795  0.0    0\n",
      "2018-09-10  5085  13.33  2.08  795  0.0    0\n",
      "2018-09-11  5085  13.08  2.05  795  0.0    0\n",
      "2018-09-12  5085  13.02  2.04  795  0.0    0\n",
      "2018-09-13  5085  12.96  2.03  795  0.0    0\n",
      "...          ...    ...   ...  ...  ...  ...\n",
      "2024-07-29  4574   0.00  0.76    0  0.0    0\n",
      "2024-07-30  4574   0.00  0.75    0  0.0    0\n",
      "2024-07-31  4574   0.00  0.75    0  0.0    0\n",
      "2024-08-01  4574   0.00  0.76    0  0.0    0\n",
      "2024-08-02  4574   0.00  0.72    0  0.0    0\n",
      "\n",
      "[1454 rows x 6 columns]\n",
      "              시가    고가    저가    종가    거래량       등락률\n",
      "날짜                                                 \n",
      "2014-06-23  4374  4374  4374  4374      0       NaN\n",
      "2014-06-24  4374  4374  4374  4374      0  0.000000\n",
      "2014-06-25  4374  4374  4374  4374      0  0.000000\n",
      "2014-06-26  4374  4374  4374  4374      0  0.000000\n",
      "2014-06-27  4374  4374  4374  4374      0  0.000000\n",
      "...          ...   ...   ...   ...    ...       ...\n",
      "2024-07-29  3425  3520  3425  3475  10528  0.000000\n",
      "2024-07-30  3505  3505  3400  3435   8456 -1.151079\n",
      "2024-07-31  3415  3440  3335  3430  11140 -0.145560\n",
      "2024-08-01  3430  3465  3370  3460   8971  0.874636\n",
      "2024-08-02  3460  3460  3265  3300  20525 -4.624277\n",
      "\n",
      "[2490 rows x 6 columns]\n",
      "                   시가총액    거래량      거래대금     상장주식수\n",
      "날짜                                                \n",
      "2014-05-30  28697587100   1000   8500000   3153581\n",
      "2014-06-02  27846120230    200   1766000   3153581\n",
      "2014-06-03  26458544590    200   1678000   3153581\n",
      "2014-06-05  26805438500    500   4250000   3153581\n",
      "2014-06-09  28697587100    500   4590000   3153581\n",
      "...                 ...    ...       ...       ...\n",
      "2024-07-29  45220710150  10528  36415010  13013154\n",
      "2024-07-30  44700183990   8456  29176385  13013154\n",
      "2024-07-31  44635118220  11140  37561820  13013154\n",
      "2024-08-01  45025512840   8971  30841995  13013154\n",
      "2024-08-02  42943408200  20525  68299070  13013154\n",
      "\n",
      "[2504 rows x 4 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 166\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_normalized_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_value\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m#cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m#conn.commit()\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m no.8 pass condition\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32me:\\아경\\AI\\Python38\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\아경\\AI\\Python38\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\아경\\AI\\Python38\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32me:\\아경\\AI\\Python38\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[70], line 163\u001b[0m, in \u001b[0;36mcalculate_normalized_value\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_normalized_value\u001b[39m(row):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_close\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotnull(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_close\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_close\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_close\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_close\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m/\u001b[39m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_close\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_close\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pymysql\n",
    "import configparser\n",
    "from pykrx import stock\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "ticker = '197140'\n",
    "\n",
    "# 대기 시간 설정 함수\n",
    "def random_sleep(min_seconds=6, max_seconds=11):\n",
    "    time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "    \n",
    "\"\"\"\n",
    "# 설정 파일 읽기\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "username = config['mysql']['username']\n",
    "password = config['mysql']['password']\n",
    "host = config['mysql']['host']\n",
    "database = config['mysql']['database']\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ConfigParser 객체 생성\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# config.ini 파일 경로 설정\n",
    "config_file_path = 'E:\\\\AI\\\\pythonProject\\\\venv\\\\masicsplit\\\\config.ini'\n",
    "\n",
    "# 경로가 올바른지 확인\n",
    "if os.path.exists(config_file_path):\n",
    "    print(\"config.ini 파일을 찾았습니다.\")\n",
    "    config.read(config_file_path)\n",
    "else:\n",
    "    print(\"config.ini 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "\n",
    "# mysql 섹션에서 설정값 가져오기\n",
    "try:\n",
    "    username = config['mysql']['user']\n",
    "    password = config['mysql']['password']\n",
    "    host = config['mysql']['host']\n",
    "    database=config['mysql']['database']\n",
    "    print(f\"Username: {username}, Password: {password}, Host: {host}\")\n",
    "except KeyError as e:\n",
    "    print(f\"설정 파일에서 키를 찾을 수 없습니다: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"기타 오류 발생: {e}\")\n",
    "    \n",
    "    \n",
    "conn = pymysql.connect(host=host, user=username, password=password, db=database, charset='utf8')\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 조건 설정\n",
    "per_threshold = 50\n",
    "pbr_threshold = 10\n",
    "div_threshold = 0  # 기준금리 참조\n",
    "\n",
    "# 현재 날짜 기준으로 최근 월 종목 리스트 수집\n",
    "current_date = datetime.datetime.now()\n",
    "last_month_str = current_date.strftime(\"%Y%m\") + '01'\n",
    "\n",
    "\n",
    "# 데이터베이스에서 마지막 날짜 확인\n",
    "cur.execute(f\"SELECT MAX(date) FROM stock_data WHERE ticker = '{ticker}'\")\n",
    "last_date = cur.fetchone()[0]\n",
    "# 새 데이터를 가져옴\n",
    "if last_date:\n",
    "    start_date = (last_date + datetime.timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "else:\n",
    "    start_date = \"19800102\"\n",
    "end_date = current_date.strftime(\"%Y%m%d\")\n",
    "print(last_date,start_date,end_date)\n",
    "df2 = stock.get_market_fundamental(start_date, end_date, ticker)\n",
    "print(df2)\n",
    "df1 = stock.get_market_ohlcv(start_date, end_date, ticker)\n",
    "print(df1)\n",
    "if '고가' not in df1.columns:\n",
    "\n",
    "    print(f'{ticker} no.6 pass condition')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1fa6273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   시가총액    거래량      거래대금     상장주식수\n",
      "날짜                                                \n",
      "2014-05-30  28697587100   1000   8500000   3153581\n",
      "2014-06-02  27846120230    200   1766000   3153581\n",
      "2014-06-03  26458544590    200   1678000   3153581\n",
      "2014-06-05  26805438500    500   4250000   3153581\n",
      "2014-06-09  28697587100    500   4590000   3153581\n",
      "...                 ...    ...       ...       ...\n",
      "2024-07-29  45220710150  10528  36415010  13013154\n",
      "2024-07-30  44700183990   8456  29176385  13013154\n",
      "2024-07-31  44635118220  11140  37561820  13013154\n",
      "2024-08-01  45025512840   8971  30841995  13013154\n",
      "2024-08-02  42943408200  20525  68299070  13013154\n",
      "\n",
      "[2504 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df3 = stock.get_market_cap(start_date, end_date, ticker)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f3138d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index(inplace=True)\n",
    "df2.reset_index(inplace=True)\n",
    "df3.reset_index(inplace=True)\n",
    "# 컬럼명 통일\n",
    "df1.rename(columns={\n",
    "    '날짜': 'date',\n",
    "    '시가': 'open',\n",
    "    '고가': 'high',\n",
    "    '저가': 'low',\n",
    "    '종가': 'close',\n",
    "    '거래량': 'volume',\n",
    "    \n",
    "}, inplace=True)\n",
    "\n",
    "df2.rename(columns={\n",
    "    '날짜': 'date',\n",
    "    'PER': 'PER',\n",
    "    'PBR': 'PBR',\n",
    "    'DIV': 'dividend',\n",
    "    'BPS': 'BPS',\n",
    "    'EPS': 'EPS',\n",
    "    'DPS': 'DPS'\n",
    "}, inplace=True)\n",
    "\n",
    "df3.rename(columns={\n",
    "    '날짜': 'date',\n",
    "    '시가총액': 'market_cap',\n",
    "    '상장주식수': 'shares_outstanding',\n",
    "    '거래대금': 'value',\n",
    "    '거래량': 'volume'\n",
    "    \n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "    # 날짜 기준으로 결합하고 중복된 열 제거\n",
    "merged_df = pd.merge(df1, df2, on='date', how='outer', suffixes=('', '_duplicate'))\n",
    "merged_df = pd.merge(merged_df, df3, on='date', how='left', suffixes=('', '_duplicate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "819c170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df\n",
    "# CSV 파일로 저장 (인덱스 없이 저장)\n",
    "merged_df.to_csv('merged_data3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 중복된 열 제거\n",
    "for column in merged_df.columns:\n",
    "    if 'duplicate' in column:\n",
    "        base_column = column.replace('_duplicate', '')\n",
    "        if base_column in merged_df.columns:\n",
    "            merged_df.drop(column, axis=1, inplace=True)\n",
    "    \n",
    "# 필요한 열만 남기기\n",
    "merged_df = merged_df[['date', 'open', 'high', 'low', 'close', 'volume', 'value', 'market_cap', 'shares_outstanding', 'PER', 'PBR', 'dividend', 'BPS', 'EPS', 'DPS']]\n",
    "# merged_df 상태 출력\n",
    "\n",
    "# NaN 값을 None으로 변환 (개별적으로 처리)\n",
    "merged_df = merged_df.replace({np.nan: None})\n",
    "# # merged_df 상태 출력\n",
    "# print(\"merged_df:\")\n",
    "# print(merged_df.head())\n",
    "\n",
    "name = stock.get_market_ticker_name(ticker)\n",
    "merged_df['ticker'] = ticker\n",
    "merged_df['name'] = name\n",
    "# 기존 데이터를 가져와서 새로운 데이터와 결합\n",
    "if last_date:\n",
    "    cur.execute(f\"SELECT * FROM stock_data WHERE ticker = '{ticker}' AND date <= '{last_date}'\")\n",
    "    existing_data = pd.DataFrame(cur.fetchall(), columns=['ticker', 'name', 'date', 'open', 'high', 'low', 'close', 'volume', 'value', 'market_cap', 'shares_outstanding', 'PER', 'PBR', 'dividend', 'BPS', 'EPS', 'DPS','normalized_value'])\n",
    "    existing_data['date'] = pd.to_datetime(existing_data['date'])\n",
    "    existing_data.set_index('date', inplace=True)\n",
    "    merged_df.set_index('date', inplace=True)\n",
    "    combined_df = pd.concat([existing_data, merged_df], axis=0, join='outer')\n",
    "        # 여기서 결합 전에 각 데이터프레임 확인\n",
    "\n",
    "        \n",
    "else: # 기존데이터가 없으면 로드된 세 DF만 결합\n",
    "    combined_df = merged_df\n",
    "    # print(combined_df)\n",
    "combined_df['min_close'] = combined_df['close'].rolling(window=252*5, min_periods=252).min()\n",
    "combined_df['max_close'] = combined_df['close'].rolling(window=252*5, min_periods=252).max()\n",
    "# 각 행에 대해 'min_close'와 'max_close'가 0이 아닌지 확인하여 'normalized_value' 계산\n",
    "def calculate_normalized_value(row):\n",
    "    if pd.notnull(row['min_close']) and pd.notnull(row['max_close']) and (row['max_close'] - row['min_close']) != 0:\n",
    "        return (row['close'] - row['min_close']) / (row['max_close'] - row['min_close']) * 100\n",
    "    else:\n",
    "        return None\n",
    "combined_df['normalized_value'] = combined_df.apply(calculate_normalized_value, axis=1)\n",
    "\n",
    "if combined_df['normalized_value'].isnull().all():\n",
    "    #cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "    #conn.commit()\n",
    "    print(f'{ticker} no.8 pass condition')\n",
    "combined_df.reset_index(inplace=True)\n",
    "\n",
    "combined_df = combined_df.replace({np.nan: None})    \n",
    "# 데이터베이스에 저장\n",
    "for _, row in combined_df.iterrows():\n",
    "    sql = '''\n",
    "    INSERT INTO stock_data (ticker, name, date, open, high, low, close, volume, value, market_cap, shares_outstanding, PER, PBR, dividend, BPS, EPS, DPS, normalized_value)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "        open=VALUES(open),\n",
    "        high=VALUES(high),\n",
    "        low=VALUES(low),\n",
    "        close=VALUES(close),\n",
    "        volume=VALUES(volume),\n",
    "        value=VALUES(value),\n",
    "        market_cap=VALUES(market_cap),\n",
    "        shares_outstanding=VALUES(shares_outstanding),\n",
    "        PER=VALUES(PER),\n",
    "        PBR=VALUES(PBR),\n",
    "        dividend=VALUES(dividend),\n",
    "        BPS=VALUES(BPS),\n",
    "        EPS=VALUES(EPS),\n",
    "        DPS=VALUES(DPS),\n",
    "        normalized_value=VALUES(normalized_value)\n",
    "    '''\n",
    "    cur.execute(sql, (\n",
    "        row['ticker'],\n",
    "        row['name'],\n",
    "        row['date'].strftime('%Y-%m-%d') if row['date'] else None,\n",
    "        row['open'],\n",
    "        row['high'],\n",
    "        row['low'],\n",
    "        row['close'],\n",
    "        int(row['volume']) if row['volume'] is not None else None,\n",
    "        int(row['value']) if row['value'] is not None else None,\n",
    "        int(row['market_cap']) if row['market_cap'] is not None else None,\n",
    "        int(row['shares_outstanding']) if row['shares_outstanding'] is not None else None,\n",
    "        row['PER'],\n",
    "        row['PBR'],\n",
    "        row['dividend'],\n",
    "        row['BPS'],\n",
    "        row['EPS'],\n",
    "        row['DPS'],\n",
    "        row['normalized_value']\n",
    "    ))\n",
    "\n",
    "conn.commit()\n",
    "    # 최근 60일 동안 데이터가 있는지 확인\n",
    "last_recorded_date = pd.to_datetime(combined_df['date']).max()\n",
    "if (current_date - last_recorded_date).days > 60:\n",
    "    print(current_date - last_recorded_date,current_date,last_recorded_date)\n",
    "    cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "    conn.commit()\n",
    "print(f\"{ticker} 데이터베이스에 저장 완료\")\n",
    "random_sleep()  \n",
    "\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"모든 데이터가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f1ae9",
   "metadata": {},
   "source": [
    "## ETF 이름 & 티커 리스트 생성  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8203cf2a-763d-497a-8b5c-474809798158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롬 드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')  # 브라우저 창을 띄우지 않음\n",
    "options.add_argument('disable-gpu')  # GPU 가속 비활성화\n",
    "options.add_argument('lang=ko_KR')  # 한국어 페이지\n",
    "\n",
    "# 크롬 드라이버 초기화\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d37eebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel 파일로 저장되었습니다: etf_list.xlsx\n",
      "MySQL 데이터베이스에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import configparser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# 설정 파일 읽기\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "username = config['mysql']['username']\n",
    "password = config['mysql']['password']\n",
    "host = config['mysql']['host']\n",
    "database = config['mysql']['database']\n",
    "\n",
    "# MySQL 연결\n",
    "conn = pymysql.connect(host=host, user=username, password=password, db=database, charset='utf8')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 크롬 드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')  # 브라우저 창을 띄우지 않음\n",
    "options.add_argument('disable-gpu')  # GPU 가속 비활성화\n",
    "options.add_argument('lang=ko_KR')  # 한국어 페이지\n",
    "\n",
    "# 크롬 드라이버 초기화\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "# URL에서 HTML 컨텐츠를 가져옴\n",
    "url = 'https://finance.naver.com/sise/etf.naver'\n",
    "driver.get(url)\n",
    "\n",
    "# 종목명과 티커를 추출하여 리스트로 저장\n",
    "etf_data = []\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, '#etfItemTable > tr')\n",
    "for row in rows:\n",
    "    name_col = row.find_elements(By.CSS_SELECTOR, 'td.ctg a')\n",
    "    if name_col:\n",
    "        name = name_col[0].text.strip()\n",
    "        ticker = name_col[0].get_attribute('href').split('=')[-1]  # 종목명 링크에서 티커 추출\n",
    "        etf_data.append([name, ticker])\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame(etf_data, columns=['종목명', '티커'])\n",
    "\n",
    "# DataFrame을 Excel 파일로 저장\n",
    "excel_filename = 'etf_list.xlsx'\n",
    "df.to_excel(excel_filename, index=False)\n",
    "print(f\"Excel 파일로 저장되었습니다: {excel_filename}\")\n",
    "\n",
    "# DataFrame을 MySQL에 저장\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS etf_list (\n",
    "    name VARCHAR(100),\n",
    "    ticker VARCHAR(20),\n",
    "    PRIMARY KEY (ticker)\n",
    ")\n",
    "'''\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# MySQL에 데이터 삽입\n",
    "for index, row in df.iterrows():\n",
    "    insert_query = '''\n",
    "    INSERT INTO etf_list (name, ticker) VALUES (%s, %s)\n",
    "    ON DUPLICATE KEY UPDATE name=VALUES(name)\n",
    "    '''\n",
    "    cur.execute(insert_query, (row['종목명'], row['티커']))\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"MySQL 데이터베이스에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77488bde",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'시장'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tickers \u001b[38;5;241m=\u001b[39m \u001b[43mstock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index_ticker_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pykrx\\stock\\stock_api.py:33\u001b[0m, in \u001b[0;36mmarket_valid_check.<locals>._market_valid_check.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarket 옵션이 올바르지 않습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame()\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pykrx\\stock\\stock_api.py:1231\u001b[0m, in \u001b[0;36mget_index_ticker_list\u001b[1;34m(date, market)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     date \u001b[38;5;241m=\u001b[39m krx\u001b[38;5;241m.\u001b[39mdatetime2string(date)\n\u001b[0;32m   1229\u001b[0m date \u001b[38;5;241m=\u001b[39m date\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkrx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexTicker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ticker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pykrx\\website\\krx\\market\\ticker.py:111\u001b[0m, in \u001b[0;36mIndexTicker.get_ticker\u001b[1;34m(self, market, date)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ticker\u001b[39m(\u001b[38;5;28mself\u001b[39m, market, date):\n\u001b[1;32m--> 111\u001b[0m     cond \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m시장\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m market) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m기준일\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m date)\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[cond]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '시장'"
     ]
    }
   ],
   "source": [
    "tickers = stock.get_index_ticker_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
